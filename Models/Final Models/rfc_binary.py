# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VAbVRyLBpKFhE2brxd7--14bwT3QpbJg
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.decomposition import PCA
from sklearn.feature_selection import mutual_info_classif

# Read the data
df = pd.read_csv('/scratch/sravic23/NIDS/datasets/csv_preprocessed.csv', low_memory=False)
print(df.shape)

# Convert 'Attack Type' column to binary
df['Attack Type'] = df['Attack Type'].apply(lambda x: 0 if x == 0 else 1)

# Train Test split
X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['Attack Type']), df['Attack Type'],
                                                    test_size=0.15,
                                                    random_state=42)

X_train = pd.DataFrame(X_train, columns=df.drop(columns=['Attack Type']).columns.to_list())
X_test = pd.DataFrame(X_test, columns=df.drop(columns=['Attack Type']).columns.to_list())
y_train = pd.DataFrame(y_train, columns=['Attack Type'])
y_test = pd.DataFrame(y_test, columns=['Attack Type'])

print("Training dataset size:", X_train.shape)
print("Testing dataset size:", X_test.shape)
print("Training target size:", y_train.shape)
print("Testing target size:", y_test.shape)

# Perform mutual information feature selection on training set
mutual_info_arr = mutual_info_classif(X_train, y_train)
top_features = X_train.columns[np.argsort(mutual_info_arr)[::-1][:15]]
X_train_selected = X_train[top_features]
X_test_selected = X_test[top_features]

# Perform PCA on selected features
pca = PCA(n_components=15)
X_train_pca = pca.fit_transform(X_train_selected)
X_test_pca = pca.transform(X_test_selected)

# Define the specific hyperparameters
best_params = {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}

# Initialize Random Forest Classifier with specific hyperparameters
rfc = RandomForestClassifier(**best_params, random_state=42)

# Initialize StratifiedKFold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Lists to store evaluation metrics across folds
accuracy_scores = []
precision_scores = []
recall_scores = []
f1_scores = []
roc_auc_scores = []

# Perform k-fold cross-validation
for train_index, test_index in skf.split(X_train_pca, y_train):
    X_train_fold, X_val_fold = X_train_pca[train_index], X_train_pca[test_index]
    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]

# Fit the model on the training fold
    rfc.fit(X_train_fold, y_train_fold)

# Predict on the validation fold
    y_val_pred = rfc.predict(X_val_fold)

# Evaluate the model on the validation fold
    accuracy_fold = accuracy_score(y_val_fold, y_val_pred)
    precision_fold = precision_score(y_val_fold, y_val_pred)
    recall_fold = recall_score(y_val_fold, y_val_pred)
    f1_fold = f1_score(y_val_fold, y_val_pred)
    roc_auc_fold = roc_auc_score(y_val_fold, rfc.predict_proba(X_val_fold)[:, 1])

# Append scores to lists
    accuracy_scores.append(accuracy_fold)
    precision_scores.append(precision_fold)
    recall_scores.append(recall_fold)
    f1_scores.append(f1_fold)
    roc_auc_scores.append(roc_auc_fold)

# Average the evaluation metrics across folds
average_accuracy = np.mean(accuracy_scores)
average_precision = np.mean(precision_scores)
average_recall = np.mean(recall_scores)
average_f1 = np.mean(f1_scores)
average_roc_auc = np.mean(roc_auc_scores)

# Predict on the X_test dataset
y_test_pred = rfc.predict(X_test_pca)

# Evaluate the model on the X_test dataset
accuracy_test = accuracy_score(y_test, y_test_pred)
precision_test = precision_score(y_test, y_test_pred)
recall_test = recall_score(y_test, y_test_pred)
f1_test = f1_score(y_test, y_test_pred)
roc_auc_test = roc_auc_score(y_test, rfc.predict_proba(X_test_pca)[:, 1])

# Print the average scores and accuracy on test dataset
print(f'Average Accuracy (cross-validation): {average_accuracy}')
print(f'Average Precision (cross-validation): {average_precision}')
print(f'Average Recall (cross-validation): {average_recall}')
print(f'Average F1 Score (cross-validation): {average_f1}')
print(f'Average ROC AUC Score (cross-validation): {average_roc_auc}')
print('\n')
print(f'Accuracy (test dataset): {accuracy_test}')
print(f'Precision (test dataset): {precision_test}')
print(f'Recall (test dataset): {recall_test}')
print(f'F1 Score (test dataset): {f1_test}')
print(f'ROC AUC Score (test dataset): {roc_auc_test}')

#Plotting the confusion matrix
plt.figure(figsize=(10,8))
sns.heatmap(cm_df, annot=True, fmt='d')
plt.title('Confusion Matrix')
plt.ylabel('Actual Values')
plt.xlabel('Predicted Values')
plt.savefig('randomforest_confusion_matrix_binary_class_classification.png')