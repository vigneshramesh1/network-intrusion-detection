{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e4635cb-5524-4cc8-b8f4-e0785da35d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5159414b-866a-412f-818d-dfc97497d721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1215675 entries, 0 to 1215674\n",
      "Data columns (total 63 columns):\n",
      " #   Column        Non-Null Count    Dtype  \n",
      "---  ------        --------------    -----  \n",
      " 0   Dur           1215675 non-null  float64\n",
      " 1   sTos          1215675 non-null  float64\n",
      " 2   dTos          1215675 non-null  float64\n",
      " 3   sTtl          1215675 non-null  float64\n",
      " 4   dTtl          1215675 non-null  float64\n",
      " 5   sHops         1215675 non-null  float64\n",
      " 6   dHops         1215675 non-null  float64\n",
      " 7   TotPkts       1215675 non-null  float64\n",
      " 8   SrcPkts       1215675 non-null  float64\n",
      " 9   DstPkts       1215675 non-null  float64\n",
      " 10  TotBytes      1215675 non-null  float64\n",
      " 11  SrcBytes      1215675 non-null  float64\n",
      " 12  DstBytes      1215675 non-null  float64\n",
      " 13  Offset        1215675 non-null  float64\n",
      " 14  sMeanPktSz    1215675 non-null  float64\n",
      " 15  dMeanPktSz    1215675 non-null  float64\n",
      " 16  Load          1215675 non-null  float64\n",
      " 17  SrcLoad       1215675 non-null  float64\n",
      " 18  DstLoad       1215675 non-null  float64\n",
      " 19  Loss          1215675 non-null  float64\n",
      " 20  SrcLoss       1215675 non-null  float64\n",
      " 21  DstLoss       1215675 non-null  float64\n",
      " 22  pLoss         1215675 non-null  float64\n",
      " 23  SrcGap        1215675 non-null  float64\n",
      " 24  DstGap        1215675 non-null  float64\n",
      " 25  Rate          1215675 non-null  float64\n",
      " 26  SrcRate       1215675 non-null  float64\n",
      " 27  DstRate       1215675 non-null  float64\n",
      " 28  SrcWin        1215675 non-null  float64\n",
      " 29  DstWin        1215675 non-null  float64\n",
      " 30  SrcTCPBase    1215675 non-null  float64\n",
      " 31  DstTCPBase    1215675 non-null  float64\n",
      " 32  TcpRtt        1215675 non-null  float64\n",
      " 33  SynAck        1215675 non-null  float64\n",
      " 34  AckDat        1215675 non-null  float64\n",
      " 35  Proto_icmp    1215675 non-null  float64\n",
      " 36  Proto_sctp    1215675 non-null  float64\n",
      " 37  Proto_tcp     1215675 non-null  float64\n",
      " 38  Proto_udp     1215675 non-null  float64\n",
      " 39  sDSb_52       1215675 non-null  float64\n",
      " 40  sDSb_af11     1215675 non-null  float64\n",
      " 41  sDSb_af12     1215675 non-null  float64\n",
      " 42  sDSb_af41     1215675 non-null  float64\n",
      " 43  sDSb_cs0      1215675 non-null  float64\n",
      " 44  sDSb_cs6      1215675 non-null  float64\n",
      " 45  sDSb_cs7      1215675 non-null  float64\n",
      " 46  sDSb_ef       1215675 non-null  float64\n",
      " 47  dDSb_af11     1215675 non-null  float64\n",
      " 48  dDSb_af12     1215675 non-null  float64\n",
      " 49  dDSb_cs0      1215675 non-null  float64\n",
      " 50  dDSb_cs1      1215675 non-null  float64\n",
      " 51  dDSb_ef       1215675 non-null  float64\n",
      " 52  Cause_Start   1215675 non-null  float64\n",
      " 53  Cause_Status  1215675 non-null  float64\n",
      " 54  State_ACC     1215675 non-null  float64\n",
      " 55  State_CON     1215675 non-null  float64\n",
      " 56  State_ECO     1215675 non-null  float64\n",
      " 57  State_FIN     1215675 non-null  float64\n",
      " 58  State_INT     1215675 non-null  float64\n",
      " 59  State_REQ     1215675 non-null  float64\n",
      " 60  State_RST     1215675 non-null  float64\n",
      " 61  State_URP     1215675 non-null  float64\n",
      " 62  Attack Type   1215675 non-null  int64  \n",
      "dtypes: float64(62), int64(1)\n",
      "memory usage: 584.3 MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('csv_preprocessed.csv')\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aa15af3-806f-4d03-83be-e3fe61e1c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Attack Type\"])\n",
    "Y = data[\"Attack Type\"]\n",
    "\n",
    "def mutual_info(X, Y):\n",
    "  mutual_info_arr = mutual_info_classif(X, Y)\n",
    "  series_info = pd.Series(mutual_info_arr)\n",
    "  series_info.index = X.columns\n",
    "  series_top = series_info.sort_values(ascending=False)[:20]\n",
    "  return series_top\n",
    "\n",
    "new_data = data[[\"SrcWin\", \"DstWin\", \"dHops\", \"dTtl\", \"TotBytes\", \"SrcBytes\", \"sMeanPktSz\", \"DstGap\", \"SrcGap\", \"dTos\", \"DstTCPBase\", \"SrcTCPBase\", \"TcpRtt\", \"Proto_udp\", \"DstBytes\", \"AckDat\" , \"dMeanPktSz\", \"Proto_tcp\", \"SynAck\", \"Load\"]]\n",
    "\n",
    "def concat_column_for_plot(pca_data, column_name):\n",
    "  for_plot = pd.concat([pca_data, data[column_name]], axis = 1)\n",
    "  return for_plot\n",
    "\n",
    "new_data = concat_column_for_plot(new_data, \"Attack Type\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_data.loc[:, new_data.columns != 'Attack Type'], new_data['Attack Type'],\n",
    "                                                    stratify=new_data['Attack Type'],\n",
    "                                                    test_size=0.15)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=new_data.columns.to_list()[:-1])\n",
    "X_test = pd.DataFrame(X_test, columns=new_data.columns.to_list()[:-1])\n",
    "y_train = pd.DataFrame(y_train, columns=['Attack Type'])\n",
    "y_test = pd.DataFrame(y_test, columns=['Attack Type'])\n",
    "\n",
    "def get_pca_df(scaled_data, no_of_components):\n",
    "\n",
    "  pca = PCA(n_components=no_of_components)\n",
    "  Principal_components=pca.fit_transform(scaled_data)\n",
    "  column_names = [\"PC \"+str(i) for i in range(1, no_of_components+1)]\n",
    "  pca_df = pd.DataFrame(data = Principal_components, columns = column_names)\n",
    "  return pca_df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4a9347d-4297-4a36-bfd8-320457ee5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41d1aedb-5fef-4d8f-86d3-f5d438f71beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23d8f436-9fc3-4857-be9c-6e82967ef22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedKNN:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = [self._predict(x) for x in X_test]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        k_distances = [distances[i] for i in k_indices]\n",
    "\n",
    "        # Calculate weights as inverse of distance\n",
    "        weights = [1/d if d != 0 else float('inf') for d in k_distances]\n",
    "        \n",
    "        # Use weighted voting to predict the class\n",
    "        class_votes = {}\n",
    "        for label, weight in zip(k_nearest_labels, weights):\n",
    "            class_votes[label] = class_votes.get(label, 0) + weight\n",
    "        return max(class_votes, key=class_votes.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c4be83a-34c2-4485-9e69-6161bfd899aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "Y = new_data['Attack Type']\n",
    "X_train, pca = get_pca_df(X_train, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26e950b0-a7c3-45d9-9525-a36fe0305c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WeightedKNN(k=3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15f4eada-8449-48eb-b5f6-3a3cbae51823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 182352 entries, 0 to 182351\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   PC 1    182352 non-null  float64\n",
      " 1   PC 2    182352 non-null  float64\n",
      " 2   PC 3    182352 non-null  float64\n",
      " 3   PC 4    182352 non-null  float64\n",
      " 4   PC 5    182352 non-null  float64\n",
      " 5   PC 6    182352 non-null  float64\n",
      " 6   PC 7    182352 non-null  float64\n",
      " 7   PC 8    182352 non-null  float64\n",
      " 8   PC 9    182352 non-null  float64\n",
      " 9   PC 10   182352 non-null  float64\n",
      " 10  PC 11   182352 non-null  float64\n",
      " 11  PC 12   182352 non-null  float64\n",
      " 12  PC 13   182352 non-null  float64\n",
      " 13  PC 14   182352 non-null  float64\n",
      " 14  PC 15   182352 non-null  float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 20.9 MB\n"
     ]
    }
   ],
   "source": [
    "x_test = pca.transform(X_test)\n",
    "x_test = pd.DataFrame(x_test, columns=X_train.columns)\n",
    "x_test.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eae8f63d-26f6-420e-83d6-d922f6cd7aae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictions)\n",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m, in \u001b[0;36mWeightedKNN.predict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_test):\n\u001b[0;32m---> 13\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(y_pred)\n",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_test):\n\u001b[0;32m---> 13\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_test]\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(y_pred)\n",
      "Cell \u001b[0;32mIn[31], line 17\u001b[0m, in \u001b[0;36mWeightedKNN._predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 17\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meuclidean_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m     k_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances)[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk]\n\u001b[1;32m     19\u001b[0m     k_nearest_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m k_indices]\n",
      "Cell \u001b[0;32mIn[31], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 17\u001b[0m     distances \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meuclidean_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x_train \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train]\n\u001b[1;32m     18\u001b[0m     k_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances)[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk]\n\u001b[1;32m     19\u001b[0m     k_nearest_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m k_indices]\n",
      "Cell \u001b[0;32mIn[31], line 10\u001b[0m, in \u001b[0;36mWeightedKNN.euclidean_distance\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meuclidean_distance\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum((\u001b[43mx1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b645a51-49d2-460f-ba7c-a678be95eace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poornimasathyakeerthi/Desktop/capstone_project/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "WeightedKNN doesn't support sample_weight.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m adaboost_classifier \u001b[38;5;241m=\u001b[39m AdaBoostClassifier(estimator\u001b[38;5;241m=\u001b[39mmodel, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAMME\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43madaboost_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/capstone_project/.venv/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/capstone_project/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:149\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    146\u001b[0m sample_weight \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Check parameters\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Clear any previous fit results\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/capstone_project/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:537\u001b[0m, in \u001b[0;36mAdaBoostClassifier._validate_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    529\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdaBoostClassifier with algorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    530\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat the weak learner supports the calculation of class \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malgorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAMME\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         )\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_fit_parameter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support sample_weight.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: WeightedKNN doesn't support sample_weight."
     ]
    }
   ],
   "source": [
    "adaboost_classifier = AdaBoostClassifier(estimator=model, n_estimators=50, algorithm='SAMME', random_state=42)\n",
    "adaboost_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176086f4-030b-4f78-9d95-a01300ff7c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
